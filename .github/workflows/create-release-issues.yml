name: Create Top 5 Release Issues
on:
  workflow_dispatch:
    inputs:
      confirm:
        description: 'Confirm issue creation (yes/no)'
        required: true
        default: 'yes'

permissions:
  issues: write
  contents: read

jobs:
  create-issues:
    runs-on: ubuntu-latest
    if: github.event.inputs.confirm == 'yes'
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Check for duplicate issues
        id: check_duplicates
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          echo "Checking for existing issues..."
          
          # Check if issues already exist
          existing=$(gh issue list --search "Fix Critical Security Headers" --json number --jq '.[].number' | head -1)
          if [ -n "$existing" ]; then
            echo "skip_security=true" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è Security headers issue already exists (#$existing)"
          else
            echo "skip_security=false" >> $GITHUB_OUTPUT
          fi
          
          existing=$(gh issue list --search "Optimize Lighthouse Performance" --json number --jq '.[].number' | head -1)
          if [ -n "$existing" ]; then
            echo "skip_lighthouse=true" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è Lighthouse issue already exists (#$existing)"
          else
            echo "skip_lighthouse=false" >> $GITHUB_OUTPUT
          fi
          
          existing=$(gh issue list --search "Fix Broken External Links" --json number --jq '.[].number' | head -1)
          if [ -n "$existing" ]; then
            echo "skip_links=true" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è Links issue already exists (#$existing)"
          else
            echo "skip_links=false" >> $GITHUB_OUTPUT
          fi
          
          existing=$(gh issue list --search "Enhance SEO and Metadata" --json number --jq '.[].number' | head -1)
          if [ -n "$existing" ]; then
            echo "skip_seo=true" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è SEO issue already exists (#$existing)"
          else
            echo "skip_seo=false" >> $GITHUB_OUTPUT
          fi
          
          existing=$(gh issue list --search "Automate ISMS Reference Validation" --json number --jq '.[].number' | head -1)
          if [ -n "$existing" ]; then
            echo "skip_isms=true" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è ISMS validation issue already exists (#$existing)"
          else
            echo "skip_isms=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Create Issue 1 - Security Headers
        if: steps.check_duplicates.outputs.skip_security == 'false'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          gh issue create \
            --title "üîí Fix Critical Security Headers (CSP, SRI, Permissions-Policy)" \
            --label "security,enhancement" \
            --body "## üéØ Objective

Resolve security findings from ZAP Full Scan by implementing proper Content Security Policy directives, Subresource Integrity attributes, and security headers across all HTML pages.

## üìã Background

ZAP security scans (Issue #355) have identified recurring security vulnerabilities:
- **CSP: script-src unsafe-inline** and **style-src unsafe-inline** - Increases XSS risk
- **Sub Resource Integrity Attribute Missing** - External resources not integrity-checked
- **CSP: Failure to Define Directive with No Fallback** - Incomplete CSP coverage
- **Insufficient Site Isolation Against Spectre Vulnerability** - Missing COOP/COEP headers

These are **medium-high priority** security findings that should be addressed before the next release.

## ‚úÖ Acceptance Criteria

- [ ] Remove \`unsafe-inline\` from CSP directives (both script-src and style-src)
- [ ] Add nonce or hash-based CSP for inline scripts/styles where required
- [ ] Implement Subresource Integrity (SRI) for all external resources (Google Fonts, CDN links)
- [ ] Add comprehensive CSP directives with proper fallbacks (default-src, img-src, etc.)
- [ ] Implement Cross-Origin headers (COOP, COEP) for Spectre mitigation
- [ ] Add Permissions-Policy header to restrict unnecessary browser features
- [ ] Verify fixes with ZAP scan showing resolved alerts
- [ ] Ensure no functionality breakage after CSP changes

## üõ†Ô∏è Implementation Guidance

### Recommended Approach: CloudFront Response Headers Policy

Since this is a static S3 + CloudFront site, implement headers via CloudFormation:

\`\`\`yaml
ResponseHeadersPolicy:
  Type: AWS::CloudFront::ResponseHeadersPolicy
  Properties:
    Name: Hack23SecurityHeaders
    SecurityHeadersConfig:
      ContentSecurityPolicy:
        ContentSecurityPolicy: \"default-src 'self'; script-src 'self'; style-src 'self' https://fonts.googleapis.com; font-src https://fonts.gstatic.com; img-src 'self' https: data:; object-src 'none'\"
        Override: true
      StrictTransportSecurity:
        AccessControlMaxAgeSec: 63072000
        IncludeSubdomains: true
        Override: true
    CustomHeadersConfig:
      Items:
        - Header: Permissions-Policy
          Value: \"geolocation=(), microphone=(), camera=()\"
        - Header: Cross-Origin-Opener-Policy
          Value: \"same-origin\"
        - Header: Cross-Origin-Embedder-Policy
          Value: \"require-corp\"
\`\`\`

### Add SRI to External Resources

Generate integrity hashes for Google Fonts and other external resources:
\`\`\`bash
curl -s https://fonts.googleapis.com/css2?family=Inter | openssl dgst -sha384 -binary | openssl base64 -A
\`\`\`

Update HTML with integrity attributes:
\`\`\`html
<link href=\"https://fonts.googleapis.com/css2?family=Inter\" 
      rel=\"stylesheet\"
      integrity=\"sha384-[HASH]\"
      crossorigin=\"anonymous\">
\`\`\`

## üìä Metadata

**Priority:** High | **Effort:** Medium (4-8 hours) | **Impact:** Resolves recurring security findings"
          sleep 2
      
      - name: Create Issue 2 - Lighthouse Performance
        if: steps.check_duplicates.outputs.skip_lighthouse == 'false'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          gh issue create \
            --title "‚ö° Optimize Lighthouse Performance Budget Compliance" \
            --label "performance,enhancement" \
            --body "## üéØ Objective

Improve website performance to consistently meet Lighthouse budget thresholds defined in \`budget.json\` for faster page loads and better user experience.

## üìã Background

Current Lighthouse budgets (from \`budget.json\`):
- **Interactive:** 7500ms target
- **First Contentful Paint:** 5000ms target  
- **Script resources:** 1000KB budget
- **Total resources:** 10MB budget

Performance optimizations will improve SEO rankings, user engagement, and reduce bounce rates.

## ‚úÖ Acceptance Criteria

- [ ] Achieve Lighthouse Performance score ‚â•90 on homepage
- [ ] Meet all timing budgets (interactive, FCP)
- [ ] Reduce total JavaScript bundle size to <1MB
- [ ] Optimize images (use WebP, proper sizing, lazy loading)
- [ ] Implement resource hints (preconnect, dns-prefetch)
- [ ] Enable text compression (Gzip/Brotli) via CloudFront
- [ ] Pass Lighthouse CI checks in GitHub Actions
- [ ] Document performance improvements with before/after metrics

## üõ†Ô∏è Implementation Guidance

### 1. Analyze Current Performance

\`\`\`bash
# Run Lighthouse locally
npm install -g lighthouse
lighthouse https://hack23.com --view
\`\`\`

### 2. Optimize Images

\`\`\`bash
# Convert PNG/JPEG to WebP (already done for some images)
# Ensure all images use:
# - WebP format with JPEG fallback
# - Proper width/height attributes
# - Lazy loading for below-fold images
\`\`\`

\`\`\`html
<img src=\"image.webp\" 
     alt=\"Description\"
     width=\"800\" 
     height=\"600\"
     loading=\"lazy\">
\`\`\`

### 3. Add Resource Hints

Add to \`<head>\` section of all HTML files:
\`\`\`html
<!-- Preconnect to external domains -->
<link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">
<link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>

<!-- DNS prefetch for less critical domains -->
<link rel=\"dns-prefetch\" href=\"https://www.googletagmanager.com\">
\`\`\`

### 4. Enable CloudFront Compression

Update CloudFormation stack to enable Brotli compression:
\`\`\`yaml
CloudFrontDistribution:
  Properties:
    DistributionConfig:
      DefaultCacheBehavior:
        Compress: true  # Enable Gzip/Brotli
\`\`\`

### 5. Defer Non-Critical CSS

For Google Fonts, use \`media\` trick:
\`\`\`html
<link rel=\"stylesheet\" 
      href=\"https://fonts.googleapis.com/css2?family=Inter\" 
      media=\"print\" 
      onload=\"this.media='all'\">
\`\`\`

### 6. Update GitHub Actions

Ensure Lighthouse CI runs with budget checks:
\`\`\`yaml
- name: Lighthouse CI
  uses: treosh/lighthouse-ci-action@v9
  with:
    urls: https://hack23.com/
    budgetPath: ./budget.json
    uploadArtifacts: true
\`\`\`

## üìä Metadata

**Priority:** Medium | **Effort:** Medium (4-6 hours) | **Impact:** Better UX, SEO, user engagement"
          sleep 2
      
      - name: Create Issue 3 - Broken Links
        if: steps.check_duplicates.outputs.skip_links == 'false'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          gh issue create \
            --title "üîó Fix Broken External Links and Documentation References" \
            --label "bug,documentation" \
            --body "## üéØ Objective

Fix broken external links identified in previous audits (Issue #344) to improve user experience and maintain professional site quality.

## üìã Background

DeadLinkChecker scan identified 35 broken links including:
- **404 errors:** Links to non-existent GitHub documentation
- **Incorrect URLs:** Allabolag company registration link
- **Localhost references:** Development URLs in production
- **Missing documentation:** Black Trigram and CIA Compliance Manager docs

## ‚úÖ Acceptance Criteria

- [ ] Fix or remove all 404 external links
- [ ] Update Allabolag company registration URL
- [ ] Remove localhost development URLs
- [ ] Verify all GitHub repository documentation links
- [ ] Update links to project documentation (SECURITY_ARCHITECTURE.md, etc.)
- [ ] Pass lychee link checker in CI (currently using \`--offline\`)
- [ ] Document any intentionally removed links

## üõ†Ô∏è Implementation Guidance

### High Priority Fixes

**1. Allabolag Company URL:**
\`\`\`html
<!-- Fix in index.html, index_sv.html -->
<!-- Current (broken): -->
<a href=\"https://www.allabolag.se/foretag/hack23-ab/-/-/2KJBPZZI0000\">

<!-- Updated: -->
<a href=\"https://www.allabolag.se/foretag/hack23-ab/g%C3%B6teborg/konsulter/2KJBPZZI5YF3I\">
\`\`\`

**2. GitHub Documentation Links:**

Check if these docs exist in respective repositories:
- \`blacktrigram\`: SECURITY_ARCHITECTURE.md, MINDMAP.md, DATA_MODEL.md, etc.
- \`cia-compliance-manager\`: docs/architecture/SECURITY_ARCHITECTURE.md
- \`cia\`: Various documentation files

If missing, either:
- Remove the link and note in release documentation
- Create placeholder docs in the target repositories
- Link to alternative existing documentation

**3. Remove Localhost URLs:**
\`\`\`bash
# Find and remove localhost references
grep -r \"localhost\" *.html
# Replace with production URLs or remove
\`\`\`

**4. Screenshot Path Issue:**
\`\`\`bash
# Fix Swedish character encoding issue
# File: cia-features.html
# Update: screenshots/Page-ministry-OVERVIEW-N√§ringsdepartementet-253.png
# Verify file exists with correct encoding
\`\`\`

### Automated Link Checking

Update \`.github/workflows/pullrequest.yml\` to enable full link checking:
\`\`\`yaml
- name: Check Links
  uses: lycheeverse/lychee-action@v2
  with:
    # Remove --offline flag to check external links
    args: --verbose --no-progress './**/*.html' './**/*.md'
    fail: true
\`\`\`

### Testing

\`\`\`bash
# Install lychee link checker
cargo install lychee

# Run local link check
lychee --verbose './**/*.html'

# Check specific problematic URLs
curl -I https://www.allabolag.se/foretag/hack23-ab/g%C3%B6teborg/konsulter/2KJBPZZI5YF3I
\`\`\`

## üìä Metadata

**Priority:** Medium | **Effort:** Small (2-4 hours) | **Impact:** Professional appearance, better UX
**Related Issues:** #344"
          sleep 2
      
      - name: Create Issue 4 - SEO Enhancement
        if: steps.check_duplicates.outputs.skip_seo == 'false'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          gh issue create \
            --title "üéØ Enhance SEO and Metadata Across All Pages" \
            --label "enhancement,seo" \
            --body "## üéØ Objective

Improve search engine visibility and social media sharing by enhancing meta tags, structured data, and SEO elements across all 74 HTML pages.

## üìã Background

Current state:
- Limited Open Graph and Twitter Card metadata
- Inconsistent page titles and descriptions  
- Missing or incomplete Schema.org structured data
- Multi-language pages (EN, SV, KO) need proper \`hreflang\` tags
- No XML sitemap optimization for blog posts

Good SEO = More organic traffic = Better visibility for security services and projects.

## ‚úÖ Acceptance Criteria

- [ ] Add complete Open Graph (og:) meta tags to all pages
- [ ] Add Twitter Card (twitter:) meta tags to all pages
- [ ] Implement Schema.org Organization and WebSite structured data
- [ ] Add \`hreflang\` tags for multi-language pages (index.html, index_sv.html, index_ko.html)
- [ ] Optimize \`<title>\` tags (50-60 characters, keywords front-loaded)
- [ ] Write compelling meta descriptions (150-160 characters)
- [ ] Update sitemap.xml with proper priority and changefreq
- [ ] Add canonical URLs to prevent duplicate content issues
- [ ] Validate with Lighthouse SEO audit (score ‚â•95)

## üõ†Ô∏è Implementation Guidance

### 1. Open Graph Meta Tags Template

Add to \`<head>\` of all pages:
\`\`\`html
<!-- Open Graph -->
<meta property=\"og:type\" content=\"website\">
<meta property=\"og:url\" content=\"https://hack23.com/[page-path]\">
<meta property=\"og:title\" content=\"[Page Title] - Hack23\">
<meta property=\"og:description\" content=\"[150-160 char description]\">
<meta property=\"og:image\" content=\"https://hack23.com/jamespethersorling.webp\">
<meta property=\"og:image:width\" content=\"1200\">
<meta property=\"og:image:height\" content=\"630\">
<meta property=\"og:site_name\" content=\"Hack23\">
<meta property=\"og:locale\" content=\"en_US\">
\`\`\`

### 2. Twitter Card Meta Tags

\`\`\`html
<!-- Twitter Card -->
<meta name=\"twitter:card\" content=\"summary_large_image\">
<meta name=\"twitter:url\" content=\"https://hack23.com/[page-path]\">
<meta name=\"twitter:title\" content=\"[Page Title] - Hack23\">
<meta name=\"twitter:description\" content=\"[150-160 char description]\">
<meta name=\"twitter:image\" content=\"https://hack23.com/jamespethersorling.webp\">
\`\`\`

### 3. Schema.org Structured Data

Add JSON-LD to homepage and key pages:
\`\`\`html
<script type=\"application/ld+json\">
{
  \"@context\": \"https://schema.org\",
  \"@type\": \"Organization\",
  \"name\": \"Hack23 AB\",
  \"url\": \"https://hack23.com\",
  \"logo\": \"https://hack23.com/jamespethersorling150.webp\",
  \"description\": \"Swedish cybersecurity consulting and gaming innovation hub\",
  \"address\": {
    \"@type\": \"PostalAddress\",
    \"addressCountry\": \"SE\",
    \"addressLocality\": \"Gothenburg\"
  },
  \"sameAs\": [
    \"https://www.linkedin.com/company/hack23/\",
    \"https://github.com/Hack23\"
  ]
}
</script>
\`\`\`

### 4. Hreflang for Multi-Language Pages

\`\`\`html
<!-- In index.html -->
<link rel=\"alternate\" hreflang=\"en\" href=\"https://hack23.com/index.html\">
<link rel=\"alternate\" hreflang=\"sv\" href=\"https://hack23.com/index_sv.html\">
<link rel=\"alternate\" hreflang=\"ko\" href=\"https://hack23.com/index_ko.html\">
<link rel=\"alternate\" hreflang=\"x-default\" href=\"https://hack23.com/index.html\">
\`\`\`

### 5. Canonical URLs

\`\`\`html
<link rel=\"canonical\" href=\"https://hack23.com/[exact-page-path]\">
\`\`\`

### 6. Optimize Sitemap.xml

Update \`sitemap.xml\` with proper priorities:
\`\`\`xml
<url>
  <loc>https://hack23.com/</loc>
  <lastmod>2025-11-11</lastmod>
  <changefreq>weekly</changefreq>
  <priority>1.0</priority>
</url>
<url>
  <loc>https://hack23.com/blog.html</loc>
  <changefreq>weekly</changefreq>
  <priority>0.9</priority>
</url>
\`\`\`

### Testing & Validation

\`\`\`bash
# Validate Open Graph tags
curl https://hack23.com/ | grep \"og:\"

# Test with validators
# - https://cards-dev.twitter.com/validator
# - https://www.opengraph.xyz/
# - https://validator.schema.org/
\`\`\`

## üìä Metadata

**Priority:** Medium | **Effort:** Medium (6-8 hours) | **Impact:** Increased organic traffic, better social sharing"
          sleep 2
      
      - name: Create Issue 5 - ISMS Validation
        if: steps.check_duplicates.outputs.skip_isms == 'false'
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          gh issue create \
            --title "‚úÖ Automate ISMS Reference Validation in CI/CD" \
            --label "automation,documentation" \
            --body "## üéØ Objective

Create automated validation to ensure all Discordian blog posts correctly link to existing ISMS policies in the Hack23/ISMS-PUBLIC repository, preventing broken references.

## üìã Background

Issue #424 identified that many blog pages link to ISMS policies that either:
- Don't exist (404 errors)
- Have been renamed or reorganized
- Are covered in different policy documents

Manual verification is error-prone. Automated validation will:
- Catch broken ISMS links during PR reviews
- Maintain accuracy as ISMS evolves
- Improve documentation quality

## ‚úÖ Acceptance Criteria

- [ ] Create validation script that checks ISMS policy links
- [ ] Integrate script into \`.github/workflows/pullrequest.yml\`
- [ ] Script should verify:
  - All \`github.com/Hack23/ISMS-PUBLIC\` links return 200 OK
  - Referenced policy files exist in ISMS repository
  - Section anchors (e.g., \`#email-security\`) exist if specified
- [ ] Generate report of broken/missing ISMS references
- [ ] Fail CI build if critical ISMS links are broken
- [ ] Update ISMS_REFERENCE_GUIDE.md with validation status
- [ ] Document validation process in README

## üõ†Ô∏è Implementation Guidance

### 1. Create Validation Script

\`\`\`bash
#!/bin/bash
# scripts/validate-isms-links.sh

echo \"üîç Validating ISMS policy references...\"

# Extract all ISMS-PUBLIC links from HTML files
isms_links=\$(grep -roh 'https://github.com/Hack23/ISMS-PUBLIC[^\"]*' *.html | sort -u)

failed=0
for link in \$isms_links; do
  echo \"Checking: \$link\"
  status=\$(curl -s -o /dev/null -w \"%{http_code}\" \"\$link\")
  
  if [ \"\$status\" != \"200\" ]; then
    echo \"‚ùå FAILED: \$link (HTTP \$status)\"
    ((failed++))
  else
    echo \"‚úÖ OK: \$link\"
  fi
  sleep 1  # Rate limiting
done

if [ \$failed -gt 0 ]; then
  echo \"‚ùå Found \$failed broken ISMS links\"
  exit 1
else
  echo \"‚úÖ All ISMS links valid\"
fi
\`\`\`

### 2. Update GitHub Actions Workflow

Add to \`.github/workflows/pullrequest.yml\`:
\`\`\`yaml
- name: Validate ISMS References
  run: |
    chmod +x scripts/validate-isms-links.sh
    ./scripts/validate-isms-links.sh
\`\`\`

### 3. Create ISMS Link Inventory

Generate mapping of blog posts to ISMS policies:
\`\`\`bash
# scripts/generate-isms-mapping.sh
#!/bin/bash

echo \"| Blog Page | ISMS Policy | Status |\"
echo \"|-----------|-------------|--------|\"

for html in discordian-*.html; do
  policies=\$(grep -o 'ISMS-PUBLIC[^\"]*\\.md' \"\$html\" | sort -u)
  if [ -n \"\$policies\" ]; then
    echo \"| \$html | \$policies | ‚úÖ |\"
  else
    echo \"| \$html | *No ISMS link* | ‚ö†Ô∏è |\"
  fi
done
\`\`\`

### 4. Advanced: Clone ISMS Repo for Local Validation

\`\`\`yaml
- name: Clone ISMS Repository
  uses: actions/checkout@v4
  with:
    repository: Hack23/ISMS-PUBLIC
    path: isms-repo
    
- name: Validate ISMS Links (Local)
  run: |
    # Check if referenced files exist
    for html in *.html; do
      policies=\$(grep -o 'ISMS-PUBLIC/blob/main/[^\"]*' \"\$html\" | sed 's|.*/blob/main/||')
      for policy in \$policies; do
        if [ ! -f \"isms-repo/\$policy\" ]; then
          echo \"‚ùå Missing: \$policy (referenced in \$html)\"
          exit 1
        fi
      done
    done
\`\`\`

### 5. Update ISMS_REFERENCE_GUIDE.md

Automatically generate reference guide:
\`\`\`bash
# Update ISMS_REFERENCE_GUIDE.md with validation status
echo \"# ISMS Reference Guide\" > ISMS_REFERENCE_GUIDE.md
echo \"\" >> ISMS_REFERENCE_GUIDE.md
echo \"Last validated: \$(date -u)\" >> ISMS_REFERENCE_GUIDE.md
./scripts/generate-isms-mapping.sh >> ISMS_REFERENCE_GUIDE.md
\`\`\`

### Testing

\`\`\`bash
# Run validation locally
./scripts/validate-isms-links.sh

# Test with intentionally broken link
echo '<a href=\"https://github.com/Hack23/ISMS-PUBLIC/blob/main/NonExistent.md\">Test</a>' > test.html
./scripts/validate-isms-links.sh  # Should fail
rm test.html
\`\`\`

## üìä Metadata

**Priority:** Medium | **Effort:** Small (2-4 hours) | **Impact:** Prevents documentation drift
**Related Issues:** #424"
      
      - name: Generate Summary
        run: |
          echo \"## üìã Top 5 Priority Issues Created for Next Release\" >> \$GITHUB_STEP_SUMMARY
          echo \"\" >> \$GITHUB_STEP_SUMMARY
          echo \"### Issues Created:\" >> \$GITHUB_STEP_SUMMARY
          echo \"1. üîí **Security Headers** - Fix CSP, SRI, and security headers (High Priority)\" >> \$GITHUB_STEP_SUMMARY
          echo \"2. ‚ö° **Lighthouse Performance** - Optimize page load times and meet budget thresholds\" >> \$GITHUB_STEP_SUMMARY
          echo \"3. üîó **Broken Links** - Fix external documentation references and 404 errors\" >> \$GITHUB_STEP_SUMMARY
          echo \"4. üéØ **SEO Enhancement** - Improve meta tags, structured data, and social sharing\" >> \$GITHUB_STEP_SUMMARY
          echo \"5. ‚úÖ **ISMS Validation** - Automate ISMS reference checking in CI/CD\" >> \$GITHUB_STEP_SUMMARY
          echo \"\" >> \$GITHUB_STEP_SUMMARY
          echo \"### Priority Assessment:\" >> \$GITHUB_STEP_SUMMARY
          echo \"- **High Priority (1):** Security headers - Resolves ZAP scan findings\" >> \$GITHUB_STEP_SUMMARY
          echo \"- **Medium Priority (4):** Performance, links, SEO, automation\" >> \$GITHUB_STEP_SUMMARY
          echo \"\" >> \$GITHUB_STEP_SUMMARY
          echo \"### Estimated Total Effort:** >> \$GITHUB_STEP_SUMMARY
          echo \"- **18-28 hours** total across all 5 issues\" >> \$GITHUB_STEP_SUMMARY
          echo \"- All issues are small-to-medium size, independently mergeable\" >> \$GITHUB_STEP_SUMMARY
          echo \"- Can be completed in parallel by multiple contributors\" >> \$GITHUB_STEP_SUMMARY
          echo \"\" >> \$GITHUB_STEP_SUMMARY
          echo \"‚úÖ Ready for next release planning!\" >> \$GITHUB_STEP_SUMMARY
